{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Using NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nltk\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "import tqdm\n",
    "from mlxtend.evaluate import paired_ttest_5x2cv\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_positive_docs = glob.glob(\"aclImdb/train/pos/*.txt\")\n",
    "train_negative_docs = glob.glob(\"aclImdb/train/neg/*.txt\")\n",
    "\n",
    "train_positive_list = []\n",
    "for i in train_positive_docs:\n",
    "    file = open(i, \"r\")\n",
    "    str = file.readline()\n",
    "    clean = re.compile('<.*?>')\n",
    "    str = re.sub(clean, ' ', str)\n",
    "    train_positive_list.append(str)\n",
    "    \n",
    "train_negative_list = []\n",
    "for i in train_negative_docs:\n",
    "    file = open(i, \"r\")\n",
    "    str = file.readline()\n",
    "    clean = re.compile('<.*?>')\n",
    "    str = re.sub(clean, ' ', str)\n",
    "    train_negative_list.append(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500, 2)\n",
      "(12500, 2)\n"
     ]
    }
   ],
   "source": [
    "labels = ['id', 'review', 'label']\n",
    "dataframe_train_positive = pd.DataFrame()\n",
    "dataframe_train_positive['review'] = train_positive_list\n",
    "dataframe_train_positive['label'] = 'positive'\n",
    "print(dataframe_train_positive.shape)\n",
    "dataframe_train_negative = pd.DataFrame()\n",
    "dataframe_train_negative['review'] = train_negative_list\n",
    "dataframe_train_negative['label'] = 'negative'\n",
    "print(dataframe_train_negative.shape)\n",
    "dataframe_train = pd.concat([dataframe_train_positive , dataframe_train_negative])\n",
    "dataframe_train=shuffle(dataframe_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5944</th>\n",
       "      <td>This is probably one of the worst French movie...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7732</th>\n",
       "      <td>Need a lesson in pure, abject failure?? Look n...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>A truly, truly dire Canadian-German co-product...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7958</th>\n",
       "      <td>SEX WISH was actually released (minus ten minu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>Sudden Impact was overall better than The Enfo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review     label\n",
       "5944  This is probably one of the worst French movie...  negative\n",
       "7732  Need a lesson in pure, abject failure?? Look n...  negative\n",
       "3534  A truly, truly dire Canadian-German co-product...  negative\n",
       "7958  SEX WISH was actually released (minus ten minu...  negative\n",
       "3770  Sudden Impact was overall better than The Enfo...  positive"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    refined_text = soup.get_text()\n",
    "    return refined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_accent_characters(text):\n",
    "    refined_text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return refined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_special_characters(text):\n",
    "    refined_text = re.sub('[^a-zA-z0-9\\s]', '', text)\n",
    "    return refined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    listOfWords = [WordNetLemmatizer().lemmatize(word) for word in text]\n",
    "    return listOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_stopwords(text, is_lower_case=False):\n",
    "    listOfWords = word_tokenize(text)\n",
    "    tokens = [word for word in listOfWords if word.isalpha()]\n",
    "    stopword_list = stopwords.words('english')\n",
    "    stopword_list.remove('no')\n",
    "    stopword_list.remove('not')\n",
    "    if is_lower_case:\n",
    "        refined_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        refined_tokens = [token for token in tokens if token.lower() not in stopword_list] \n",
    "    return refined_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate(text):\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_dataframe_text(dataframe):\n",
    "    dataframe[\"review\"] = dataframe[\"review\"].apply(eliminate_html_tags)\n",
    "    dataframe['review'] = dataframe['review'].apply(eliminate_accent_characters)\n",
    "    dataframe['review'] = dataframe['review'].str.lower()    \n",
    "    dataframe['review'] = dataframe['review'].apply(eliminate_special_characters)\n",
    "    dataframe['review'] = dataframe['review'].apply(eliminate_stopwords, True)\n",
    "    dataframe[\"review\"] = dataframe[\"review\"].apply(lemmatize_text)\n",
    "    dataframe[\"review\"] = dataframe[\"review\"].apply(concatenate)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = preprocessing_dataframe_text(dataframe_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5944</th>\n",
       "      <td>probably one worst french movie seen far among...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7732</th>\n",
       "      <td>need lesson pure abject failure look no wizard...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>truly truly dire canadiangerman coproduction e...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7958</th>\n",
       "      <td>sex wish actually released minus ten minute ah...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>sudden impact overall better enforcer opinion ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review     label\n",
       "5944  probably one worst french movie seen far among...  negative\n",
       "7732  need lesson pure abject failure look no wizard...  negative\n",
       "3534  truly truly dire canadiangerman coproduction e...  negative\n",
       "7958  sex wish actually released minus ten minute ah...  negative\n",
       "3770  sudden impact overall better enforcer opinion ...  positive"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000,)\n",
      "(15000,)\n",
      "['negative' 'positive']\n",
      "(10000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train=preprocessed_data['review'][:15000]\n",
    "y_train=preprocessed_data['label'][:15000]\n",
    "\n",
    "X_test = preprocessed_data['review'][15000:]\n",
    "y_test = preprocessed_data['label'][15000:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(y_train.unique())\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Different Vectorization Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountVec = CountVectorizer()\n",
    "BoW_fv_train=CountVec.fit_transform(X_train)\n",
    "BoW_fv_test=CountVec.transform(X_test)\n",
    "BoW_fv = CountVec.fit_transform(preprocessed_data['review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashing = HashingVectorizer(strip_accents='ascii', lowercase=True, preprocessor=None,n_features=BoW_fv.shape[1])\n",
    "hashing_fv_train=hashing.fit_transform(X_train)\n",
    "hashing_fv_test=hashing.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 74836)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(strip_accents='ascii', lowercase=True, preprocessor=None,max_features=BoW_fv.shape[1])\n",
    "tfidf_fv_train=tfidf.fit_transform(X_train)\n",
    "tfidf_fv_test=tfidf.transform(X_test)\n",
    "tfidf_fv_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.9994\n",
      "Test accuracy 0.8768\n",
      "Time to run: 1.703455924987793\n"
     ]
    }
   ],
   "source": [
    "time_beginning_of_training = time.time()\n",
    "\n",
    "model_lr_bow=LogisticRegression(random_state=0)\n",
    "train_feature = model_lr_bow.fit(BoW_fv_train, y_train)\n",
    "\n",
    "test_feature_lr_bow = model_lr_bow.predict(BoW_fv_test)\n",
    "\n",
    "train_acc=model_lr_bow.score(BoW_fv_train, y_train)\n",
    "print('Train accuracy {}'.format(train_acc))\n",
    "test_acc=model_lr_bow.score(BoW_fv_test, y_test)\n",
    "print('Test accuracy {}'.format(test_acc))\n",
    "\n",
    "time_end_of_training = time.time()\n",
    "print('Time to run: {}'.format(time_end_of_training-time_beginning_of_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     title  sample_size  train_acc  test_acc\n",
      "0  Logistic Regression BoW        25000     0.9994    0.8768\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({})\n",
    "df.reset_index(inplace=True)\n",
    "df[\"title\"]=[\"Logistic Regression BoW\"]\n",
    "df[\"sample_size\"]=[25000]\n",
    "df[\"train_acc\"]=train_acc\n",
    "df[\"test_acc\"]=test_acc\n",
    "df.drop(labels=\"index\",axis=1,inplace=True)\n",
    "print(df)\n",
    "results=pd.concat([df,results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Logistic Regression with BoW\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88      4973\n",
      "    positive       0.87      0.88      0.88      5027\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Logistic Regression with BoW\")\n",
    "print(classification_report(y_test, test_feature_lr_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.9054666666666666\n",
      "Test accuracy 0.8691\n",
      "Time to run: 4.513115882873535\n"
     ]
    }
   ],
   "source": [
    "time_beginning_of_training = time.time()\n",
    "\n",
    "model_lr_hashing=LogisticRegression(random_state=0)\n",
    "train_feature = model_lr_hashing.fit(hashing_fv_train, y_train)\n",
    "\n",
    "test_feature_lr_hashing = model_lr_hashing.predict(hashing_fv_test)\n",
    "\n",
    "train_acc=model_lr_hashing.score(hashing.transform(X_train), y_train)\n",
    "print('Train accuracy {}'.format(train_acc))\n",
    "test_acc=model_lr_hashing.score(hashing.transform(X_test), y_test)\n",
    "print('Test accuracy {}'.format(test_acc))\n",
    "\n",
    "time_end_of_training = time.time()\n",
    "print('Time to run: {}'.format(time_end_of_training-time_beginning_of_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         title  sample_size  train_acc  test_acc\n",
      "0  Logistic Regression Hashing        25000   0.905467    0.8691\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({})\n",
    "df.reset_index(inplace=True)\n",
    "df[\"title\"]=[\"Logistic Regression Hashing\"]\n",
    "df[\"sample_size\"]=[25000]\n",
    "df[\"train_acc\"]=train_acc\n",
    "df[\"test_acc\"]=test_acc\n",
    "df.drop(labels=\"index\",axis=1,inplace=True)\n",
    "print(df)\n",
    "results=pd.concat([df,results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Logistic Regression with hashing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87      4973\n",
      "    positive       0.86      0.88      0.87      5027\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Logistic Regression with hashing\")\n",
    "print(classification_report(y_test, test_feature_lr_hashing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.9378666666666666\n",
      "Test accuracy 0.8863\n",
      "Time to run: 3.5468521118164062\n"
     ]
    }
   ],
   "source": [
    "time_beginning_of_training = time.time()\n",
    "\n",
    "model_lr_tfidf=LogisticRegression(random_state=0)\n",
    "model_lr_tfidf.fit(tfidf_fv_train, y_train)\n",
    "\n",
    "test_feature_lr_tfidf = model_lr_tfidf.predict(tfidf_fv_test)\n",
    "\n",
    "train_acc=model_lr_tfidf.score(tfidf.transform(X_train), y_train)\n",
    "print('Train accuracy {}'.format(train_acc))\n",
    "test_acc=model_lr_tfidf.score(tfidf.transform(X_test), y_test)\n",
    "print('Test accuracy {}'.format(test_acc))\n",
    "\n",
    "time_end_of_training = time.time()\n",
    "print('Time to run: {}'.format(time_end_of_training-time_beginning_of_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       title  sample_size  train_acc  test_acc\n",
      "0  Logistic Regression Tfidf        25000   0.937867    0.8863\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({})\n",
    "df.reset_index(inplace=True)\n",
    "df[\"title\"]=[\"Logistic Regression Tfidf\"]\n",
    "df[\"sample_size\"]=[25000]\n",
    "df[\"train_acc\"]=train_acc\n",
    "df[\"test_acc\"]=test_acc\n",
    "df.drop(labels=\"index\",axis=1,inplace=True)\n",
    "print(df)\n",
    "results=pd.concat([df,results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Logistic Regression with Tfidf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.88      4973\n",
      "    positive       0.88      0.90      0.89      5027\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Logistic Regression with Tfidf\")\n",
    "print(classification_report(y_test, test_feature_lr_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier with Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 1.0\n",
      "Test accuracy 0.8502\n"
     ]
    }
   ],
   "source": [
    "model_rfc_hashing=RandomForestClassifier(random_state=0)\n",
    "model_rfc_hashing.fit(hashing.fit_transform(X_train), y_train)\n",
    "\n",
    "test_model_rfc_hashing = model_rfc_hashing.predict(hashing.transform(X_test))\n",
    "\n",
    "train_acc=model_rfc_hashing.score(hashing.transform(X_train), y_train)\n",
    "print('Train accuracy {}'.format(train_acc))\n",
    "test_acc=model_rfc_hashing.score(hashing.transform(X_test), y_test)\n",
    "print('Test accuracy {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            title  sample_size  train_acc  test_acc\n",
      "0  RandomForestClassifier Hashing        25000        1.0    0.8502\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({})\n",
    "df.reset_index(inplace=True)\n",
    "df[\"title\"]=[\"RandomForestClassifier Hashing\"]\n",
    "df[\"sample_size\"]=[25000]\n",
    "df[\"train_acc\"]=train_acc\n",
    "df[\"test_acc\"]=test_acc\n",
    "df.drop(labels=\"index\",axis=1,inplace=True)\n",
    "print(df)\n",
    "results=pd.concat([df,results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for RandomForestClassifier with Hashing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85      4973\n",
      "    positive       0.86      0.84      0.85      5027\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for RandomForestClassifier with Hashing\")\n",
    "print(classification_report(y_test, test_model_rfc_hashing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier with Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 1.0\n",
      "Test accuracy 0.8413\n"
     ]
    }
   ],
   "source": [
    "model_rfc_tfidf=RandomForestClassifier(random_state=0)\n",
    "model_rfc_tfidf.fit(tfidf.fit_transform(X_train), y_train)\n",
    "\n",
    "test_feature_rfc_tfidf = model_rfc_tfidf.predict(tfidf.transform(X_test))\n",
    "\n",
    "train_acc=model_rfc_tfidf.score(tfidf.transform(X_train), y_train)\n",
    "print('Train accuracy {}'.format(train_acc))\n",
    "test_acc=model_rfc_tfidf.score(tfidf.transform(X_test), y_test)\n",
    "print('Test accuracy {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          title  sample_size  train_acc  test_acc\n",
      "0  RandomForestClassifier Tfidf        25000        1.0    0.8413\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({})\n",
    "df.reset_index(inplace=True)\n",
    "df[\"title\"]=[\"RandomForestClassifier Tfidf\"]\n",
    "df[\"sample_size\"]=[25000]\n",
    "df[\"train_acc\"]=train_acc\n",
    "df[\"test_acc\"]=test_acc\n",
    "df.drop(labels=\"index\",axis=1,inplace=True)\n",
    "print(df)\n",
    "results=pd.concat([df,results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for RandomForestClassifier with Tfidf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.85      0.84      4973\n",
      "    positive       0.85      0.83      0.84      5027\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for RandomForestClassifier with Tfidf\")\n",
    "print(classification_report(y_test, test_feature_rfc_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC with Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.9738\n",
      "Test accuracy 0.8841\n",
      "Time to run: 2.0046639442443848\n"
     ]
    }
   ],
   "source": [
    "time_beginning_of_training = time.time()\n",
    "\n",
    "model_linearsvc_hashing =LinearSVC(random_state=0)\n",
    "model_linearsvc_hashing.fit(hashing_fv_train, y_train)\n",
    "\n",
    "test_feature_linearsvc_hashing = model_linearsvc_hashing.predict(hashing_fv_test)\n",
    "\n",
    "train_acc=model_linearsvc_hashing.score(hashing.transform(X_train), y_train)\n",
    "print('Train accuracy {}'.format(train_acc))\n",
    "test_acc=model_linearsvc_hashing.score(hashing.transform(X_test), y_test)\n",
    "print('Test accuracy {}'.format(test_acc))\n",
    "\n",
    "time_end_of_training = time.time()\n",
    "print('Time to run: {}'.format(time_end_of_training-time_beginning_of_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               title  sample_size  train_acc  test_acc\n",
      "0  LinearSVC Hashing        25000     0.9738    0.8841\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({})\n",
    "df.reset_index(inplace=True)\n",
    "df[\"title\"]=[\"LinearSVC Hashing\"]\n",
    "df[\"sample_size\"]=[25000]\n",
    "df[\"train_acc\"]=train_acc\n",
    "df[\"test_acc\"]=test_acc\n",
    "df.drop(labels=\"index\",axis=1,inplace=True)\n",
    "print(df)\n",
    "results=pd.concat([df,results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for LinearSVC with Hashing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.88      4973\n",
      "    positive       0.88      0.89      0.89      5027\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for LinearSVC with Hashing\")\n",
    "print(classification_report(y_test, test_feature_linearsvc_hashing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC with Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.9954666666666667\n",
      "Test accuracy 0.8914\n",
      "Time to run: 5.162245988845825\n"
     ]
    }
   ],
   "source": [
    "time_beginning_of_training = time.time()\n",
    "\n",
    "model_linearsvc_tfidf = LinearSVC(random_state=0)\n",
    "model_linearsvc_tfidf.fit(tfidf.fit_transform(X_train), y_train)\n",
    "\n",
    "test_model_linearsvc_tfidf = model_linearsvc_tfidf.predict(tfidf.transform(X_test))\n",
    "\n",
    "train_acc=model_linearsvc_tfidf.score(tfidf.transform(X_train), y_train)\n",
    "print('Train accuracy {}'.format(train_acc))\n",
    "\n",
    "test_acc=model_linearsvc_tfidf.score(tfidf.transform(X_test), y_test)\n",
    "print('Test accuracy {}'.format(test_acc))\n",
    "\n",
    "time_end_of_training = time.time()\n",
    "print('Time to run: {}'.format(time_end_of_training-time_beginning_of_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             title  sample_size  train_acc  test_acc\n",
      "0  LinearSVC Tfidf        25000   0.995467    0.8914\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({})\n",
    "df.reset_index(inplace=True)\n",
    "df[\"title\"]=[\"LinearSVC Tfidf\"]\n",
    "df[\"sample_size\"]=[25000]\n",
    "df[\"train_acc\"]=train_acc\n",
    "df[\"test_acc\"]=test_acc\n",
    "df.drop(labels=\"index\",axis=1,inplace=True)\n",
    "print(df)\n",
    "results=pd.concat([df,results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for LinearSVC with Tfidf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89      4973\n",
      "    positive       0.89      0.90      0.89      5027\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for LinearSVC with Tfidf\")\n",
    "print(classification_report(y_test, test_model_linearsvc_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC Tfidf</td>\n",
       "      <td>25000</td>\n",
       "      <td>0.995467</td>\n",
       "      <td>0.8914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC Hashing</td>\n",
       "      <td>25000</td>\n",
       "      <td>0.973800</td>\n",
       "      <td>0.8841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier Tfidf</td>\n",
       "      <td>25000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier Hashing</td>\n",
       "      <td>25000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Tfidf</td>\n",
       "      <td>25000</td>\n",
       "      <td>0.937867</td>\n",
       "      <td>0.8863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Hashing</td>\n",
       "      <td>25000</td>\n",
       "      <td>0.905467</td>\n",
       "      <td>0.8691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression BoW</td>\n",
       "      <td>25000</td>\n",
       "      <td>0.999400</td>\n",
       "      <td>0.8768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title  sample_size  train_acc  test_acc\n",
       "0                 LinearSVC Tfidf        25000   0.995467    0.8914\n",
       "0               LinearSVC Hashing        25000   0.973800    0.8841\n",
       "0    RandomForestClassifier Tfidf        25000   1.000000    0.8413\n",
       "0  RandomForestClassifier Hashing        25000   1.000000    0.8502\n",
       "0       Logistic Regression Tfidf        25000   0.937867    0.8863\n",
       "0     Logistic Regression Hashing        25000   0.905467    0.8691\n",
       "0         Logistic Regression BoW        25000   0.999400    0.8768"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Hypothesis Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value is 0.884\n",
      "t-statistics is -0.154\n",
      "Here p>0.05, so we can say that performance of two models are not significatly different and so cannot reject the null hypothesis\n"
     ]
    }
   ],
   "source": [
    "t, p = paired_ttest_5x2cv(estimator1=model_lr_tfidf, \n",
    "                          estimator2=model_linearsvc_tfidf, \n",
    "                          X=tfidf_fv_train, \n",
    "                          y=y_train, \n",
    "                          scoring='accuracy', \n",
    "                          random_seed=1)\n",
    "\n",
    "print(f'P-value is {p:.3f}')\n",
    "print(f't-statistics is {t:.3f}')\n",
    "\n",
    "if p <= 0.05:\n",
    "    print('Here p<0.05, so we may conclude that performance of this models are significantly different from each other and so rejecting null hypothesis')\n",
    "else:\n",
    "    print('Here p>0.05, so we can say that performance of two models are not significatly different and so cannot reject the null hypothesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value is 0.039\n",
      "t-statistics is 2.774\n",
      "Here p<0.05, so we may conclude that performance of this models are significantly different from each other and so rejecting null hypothesis\n"
     ]
    }
   ],
   "source": [
    "t, p = paired_ttest_5x2cv(estimator1=model_linearsvc_hashing, \n",
    "                          estimator2=model_rfc_hashing, \n",
    "                          X=hashing_fv_train, \n",
    "                          y=y_train, \n",
    "                          scoring='accuracy', \n",
    "                          random_seed=1)\n",
    "\n",
    "print(f'P-value is {p:.3f}')\n",
    "print(f't-statistics is {t:.3f}')\n",
    "\n",
    "if p <= 0.05:\n",
    "    print('Here p<0.05, so we may conclude that performance of this models are significantly different from each other and so rejecting null hypothesis')\n",
    "else:\n",
    "    print('Here p>0.05, so we can say that performance of two models are not significatly different and so cannot reject the null hypothesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter movie review: All I read from these reviews is how it’s “not accurate to the book” that may be true but it’s still a great film, disliking a good movie and rating it low despite the fact of it being a great movie only because of its inaccuracy is just messed up, all though I loved this movie, I will say some of the seal stuff was unrealistic, but besides all that, Michael B Jordan did what he does best and delivered a great character. I understand why people are angry, but in all it was a good film. Also, this could be leading up to a tom Clancy - cinematic - Universe (AKA) TCCU, which I am excited for. If you tell the same story you’ll know what to expect and it’ll deprive the suspense from the film. I can’t wait to see more from this series.\n"
     ]
    }
   ],
   "source": [
    "review = input(\"Please enter movie review: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Negative Review: \"Without a doubt the worst movie adaptation of a book I've ever seen.  It's hard to give it one star. The only obvious link to the book is John's change of name from Kelly to Clark at the end.  Clancy wrote a phenomenal page turner that had depth in plot and character development. This movie wasn't more than continuous scenes of gratuitous violence with little, if any meaningful or believable dialogue, and a story line that doesn't really have any relevance to the novel.  I can' believe the Clancy estate, which controls development of  the Tom Clancy related content since his death, would allow this to happen .  Anyone who read the book and saw this film, would easily agree.  Conversely, those who saw the film, without reading the book would walk away without knowledge or appreciation of Clancy's true genius. Amazon has done a much better job with it's Jack Ryan TV series in maintaining the relatable storylines and Clancy style\"\n",
    "## Positive Review: \"All I read from these reviews is how it’s “not accurate to the book” that may be true but it’s still a great film, disliking a good movie and rating it low despite the fact of it being a great movie only because of its inaccuracy is just messed up, all though I loved this movie, I will say some of the seal stuff was unrealistic, but besides all that, Michael B Jordan did what he does best and delivered a great character. I understand why people are angry, but in all it was a good film. Also, this could be leading up to a tom Clancy - cinematic - Universe (AKA) TCCU, which I am excited for. If you tell the same story you’ll know what to expect and it’ll deprive the suspense from the film. I can’t wait to see more from this series.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive']\n"
     ]
    }
   ],
   "source": [
    "input_vectorizer = TfidfVectorizer(vocabulary=tfidf.vocabulary_)\n",
    "output_vector = input_vectorizer.fit_transform([review])\n",
    "predicted_review = model_linearsvc_tfidf.predict(output_vector)\n",
    "print(predicted_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
